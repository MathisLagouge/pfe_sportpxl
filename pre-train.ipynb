{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce650d42-3558-4036-9d2b-3dcfb10ed9d5",
   "metadata": {},
   "source": [
    "This notebook is dedicated to fine-tuning the yolo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bdf8643-2100-4f9f-ae8c-049308dbcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import polars as pl\n",
    "from ultralytics import settings\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "# Update a setting\n",
    "settings.update({'mlflow': True})\n",
    "\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# dataset = \"dataset.yaml\"\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "dataset = \"dataset-seg.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5ad8c9-2e96-4783-852c-4ca677cff646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.11 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.10 ðŸš€ Python-3.11.6 torch-2.2.0+cu121 CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=dataset-seg.yaml, epochs=5, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=0, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1005055  ultralytics.nn.modules.head.Segment          [5, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3264591 parameters, 3264575 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 417/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/big_data/Files/Lessons/AI/PFE/pfe_sportpxl/data_segment/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/big_data/Files/Lessons/AI/PFE/pfe_sportpxl/data_segment/train/labels.cache.\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train2/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/09 13:55:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2024/02/09 13:55:46 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of transformers. If you encounter errors during autologging, try upgrading / downgrading transformers to a supported version, or try upgrading MLflow.\n",
      "2024/02/09 13:55:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n",
      "2024/02/09 13:55:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/09 13:55:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(57e195d008d34e69be776ba29e787af5) to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs/mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train2\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G     0.4525     0.9802      2.855     0.9661         19        640: 100%\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     M"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         43      0.113      0.977      0.934      0.829      0.115          1      0.939      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G     0.3706     0.7813      2.684     0.8718         18        640: 100%\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     M"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         43      0.125          1      0.957      0.873      0.125          1      0.957      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G     0.4174      0.719      2.452      0.895         26        640: 100%\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     M"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         43      0.134          1      0.967      0.875      0.134          1      0.967      0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G     0.4347     0.6878      2.235     0.9156         15        640: 100%\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     M"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         43       0.13          1      0.974      0.882       0.13          1      0.991      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G     0.4822      0.805      2.016     0.9429         21        640: 100%\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     M"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         43      0.139          1      0.983      0.876      0.139          1      0.993      0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train2/weights/last.pt, 6.8MB\n",
      "Optimizer stripped from runs/segment/train2/weights/best.pt, 6.8MB\n",
      "\n",
      "Validating runs/segment/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.10 ðŸš€ Python-3.11.6 torch-2.2.0+cu121 CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3259039 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         43      0.141          1      0.982      0.876      0.141          1      0.993      0.854\n",
      "                   car         40         43      0.141          1      0.982      0.876      0.141          1      0.993      0.854\n",
      "Speed: 1.0ms preprocess, 53.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train2\u001b[0m\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=dataset,\n",
    "                      device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b8109-6291-4b5a-8941-f41278bdd4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
